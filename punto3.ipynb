{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma por defecto del dataset '.csv': \n",
      " ['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity', 'Potability']\n"
     ]
    }
   ],
   "source": [
    "# 1. Cargar los datos\n",
    "datos = pd.read_csv('water_potability.csv').dropna()\n",
    "print(\"Forma por defecto del dataset '.csv': \\n\", list(datos.keys()))\n",
    "\n",
    "# 2. Preprocesar los datos si es necesario\n",
    "X = datos.drop('Potability', axis=1)\n",
    "y = datos['Potability']\n",
    "\n",
    "# 3. Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "features = list(datos.keys())\n",
    "features.remove('Potability')\n",
    "X_train3, X_temp3, y_train3, y_temp3 = train_test_split(datos[features], datos['Potability'], test_size=0.2)\n",
    "X_val3, X_test3, y_val3, y_test3 = train_test_split(X_temp3, y_temp3, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aquí secuestramos la función para normalizar que habíamos hecho en la tarea 1. Y luego la usamos para normalizar los datos de la tarea 3, en el punto 3.\n",
    "Los datos de validación y test se normalizaron con la media y la desviación de los datos de entrenamiento\n",
    "\"\"\"\n",
    "parametros_train = dict(map(lambda x: (x, {'media': np.mean(X_train3[x]), 'desviacion': np.std(X_train3[x])}), X_train3.keys()))\n",
    "def normalizar(dataSet, features, parametros = []):\n",
    "    \"\"\"\n",
    "    Esta función resta la media y luego divide entre la desviación estandar de cada dato en cada columna. Si se le especifica la media y la desviación en los parámetros \n",
    "    Usa esa media y desviación dada, de lo contrario, calcula la media y la desviación de cada columna especificada en \"features\"\n",
    "    @input: dataSet <pd.DataFrame>: Tabla de datos a la que se le va a dar normalización a la columans dadas\n",
    "    @input: features <list>: lista de \"features\" o columnas que se van a normalizar\n",
    "    @input: (opcional) parametros <dict>: En caso de que se quiera normalizar con una media y una desviación dada se especifican en un diccionario así: {'mileage':{'media': 2.9, 'desviacion': 7}}\n",
    "    \"\"\"\n",
    "    if len(parametros) == 0:\n",
    "        for feature in features:\n",
    "            media = np.mean(dataSet[feature])\n",
    "            desviacion = np.std(dataSet[feature])\n",
    "            if desviacion != 0:\n",
    "                dataSet[feature] = (dataSet[feature] - media)/desviacion\n",
    "            #fin if \n",
    "        #fin for\n",
    "    #fin if \n",
    "    else:\n",
    "        for feature in features:\n",
    "            media = parametros[feature]['media']\n",
    "            desviacion = parametros[feature]['desviacion']\n",
    "            if desviacion != 0:\n",
    "                dataSet[feature] = (dataSet[feature] - media)/desviacion\n",
    "            #fin if \n",
    "        #fin for\n",
    "#fin función\n",
    "normalizar(X_train3, features)\n",
    "normalizar(X_val3, features, parametros_train)\n",
    "normalizar(X_test3, features, parametros_train)\n",
    "X_train3['D'] = (1/len(X_train3.index))*np.ones(len(X_train3.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion_error(limite, feature, no_potables, potables):\n",
    "    no_potables_izq = no_potables[no_potables[feature] <= limite]\n",
    "    potables_izq = potables[potables[feature] <= limite]\n",
    "    no_potables_der = no_potables[no_potables[feature] > limite]\n",
    "    potables_der = potables[potables[feature] > limite]\n",
    "    D_tot_izq = sum(no_potables_izq['D']) + sum(potables_izq['D'])\n",
    "    D_tot_der = sum(no_potables_der['D']) + sum(potables_der['D'])\n",
    "    if D_tot_der == 0 or D_tot_izq == 0:\n",
    "        return 1\n",
    "    #fin if \n",
    "    x_0_izq = sum(no_potables_izq['D'])/D_tot_izq\n",
    "    x_1_izq = sum(potables_izq['D'])/D_tot_izq\n",
    "    x_0_der = sum(no_potables_der['D'])/D_tot_der\n",
    "    x_1_der = sum(potables_der['D'])/D_tot_der\n",
    "    I_izq = 1 - x_0_izq**2 - x_1_izq**2\n",
    "    I_der = 1 - x_0_der**2 - x_1_der**2\n",
    "    Impureza_total = I_izq*D_tot_izq + I_der*D_tot_der\n",
    "    return Impureza_total\n",
    "#fin función\n",
    "\n",
    "    \n",
    "def MinimizarImpureza_feature(datos, etiquetas, feature, debug = 'off'):\n",
    "    potables = datos[etiquetas == 1]\n",
    "    no_potables = datos[etiquetas == 0]\n",
    "    g_0 = no_potables['D'].dot(no_potables[feature])\n",
    "    g_1 = potables['D'].dot(potables[feature])\n",
    "    if g_0 > g_1:\n",
    "        g_mayor = g_0\n",
    "        g_menor = g_1\n",
    "        etiqueta_menor = 1\n",
    "    else:\n",
    "        g_mayor = g_1\n",
    "        g_menor = g_0\n",
    "        etiqueta_menor = 0\n",
    "    #fin if \n",
    "    if debug == 'on':\n",
    "        datos_busqueda = datos\n",
    "    else:\n",
    "        datos_busqueda = datos[(datos[feature] > g_menor) & (datos[feature] < g_mayor)]\n",
    "    #fin if \n",
    "    g_medio = sum(no_potables['D'])*g_0 + sum(potables['D'])*g_1\n",
    "    if  len(datos_busqueda) == 0:\n",
    "        return {'valor_limite': g_medio, 'etiqueta_menor': etiqueta_menor}\n",
    "    else:\n",
    "        limite_optimo = g_medio\n",
    "        impureza_optimo = funcion_error(limite_optimo, feature, no_potables, potables)\n",
    "        for i in datos_busqueda.index:\n",
    "            impureza_evaluar = funcion_error(datos_busqueda[feature][i], feature, no_potables, potables)\n",
    "            if  impureza_evaluar < impureza_optimo:\n",
    "                limite_optimo = datos_busqueda[feature][i]\n",
    "                impureza_optimo = impureza_evaluar\n",
    "            #fin if \n",
    "        #fin for \n",
    "        return {'valor_limite': limite_optimo, 'etiqueta_menor': etiqueta_menor}\n",
    "    #fin if\n",
    "#fin función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valor_limite': 3.2870716519534713, 'etiqueta_menor': 0, 'g_medio': -0.004207831814974769, 'p_opt': 0.48036624855771604}\n"
     ]
    }
   ],
   "source": [
    "print(MinimizarImpureza_feature(X_train3, y_train3, 'Solids'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, False]\n"
     ]
    }
   ],
   "source": [
    "lista = [True, True, False]\n",
    "print(lista and lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
