{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCwCKmrvlgIR"
      },
      "source": [
        "##Tarea 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7qzxoaclafZ"
      },
      "source": [
        "El objetivo de este taller es resolver el problema de clasificación de potabilidad de agua\n",
        "usando los datos adjuntos. Divida apropiadamente los datos en conjuntos de entrenamiento y\n",
        "prueba. A su vez, parte de los datos de entrenamiento se deben utilizar en los procedimientos\n",
        "de selección de modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kutG6H6BvQHq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhxWgCF2EGTe",
        "outputId": "ec9f3b38-e068-4696-e26d-f16374ed14a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forma por defecto del dataset '.csv': \n",
            " ['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity', 'Potability']\n"
          ]
        }
      ],
      "source": [
        "# 1. Cargar los datos\n",
        "datos = pd.read_csv('water_potability.csv').dropna()\n",
        "print(\"Forma por defecto del dataset '.csv': \\n\", list(datos.keys()))\n",
        "\n",
        "# 2. Preprocesar los datos si es necesario\n",
        "X = datos.drop('Potability', axis=1)\n",
        "y = datos['Potability']\n",
        "\n",
        "# Lidiar con los valores nulos, normalizar, etc.\n",
        "scaler = StandardScaler()\n",
        "X_n= scaler.fit_transform(X)\n",
        "\n",
        "# 3. Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_n, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BJeWu33lmgM"
      },
      "source": [
        "#1.\n",
        "Resuelva el problema utilizando Random Forest. Seleccione el modelo apropiado por\n",
        "validación cruzada. para esto entrene modelos con los siguientes parámetros:\n",
        "\n",
        "\n",
        "*   Número de árboles: Por lo menos 4 valores escogidos entre 100 y 500,\n",
        "*   Mínimo número de datos por hoja: Por lo menos 3 valores entre 2 y 30.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wuHG-ueVKuHB"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "t__YIxvVlJ3f"
      },
      "outputs": [],
      "source": [
        "# Configurar la grilla de parámetros para Random Forest\n",
        "params_RF = {\n",
        "    'n_estimators'      :   [100, 200, 300, 500],  # Número de árboles\n",
        "    'min_samples_leaf'  :            [2, 15, 30],  # Mínimo número de datos por hoja\n",
        "}\n",
        "\n",
        "# Crear y entrenar el clasificador Random Forest\n",
        "RF = RandomForestClassifier(random_state=42)\n",
        "cv_RF = GridSearchCV(estimator = RF, param_grid = params_RF) # Introducir los parámetros de validación cruzada\n",
        "cv_RF.fit(X_train, y_train)\n",
        "\n",
        "# Seleccionar el mejor modelo\n",
        "mejor_RF = cv_RF.best_estimator_\n",
        "\n",
        "# Evaluar el modelo seleccionado en el conjunto de prueba\n",
        "y_pred_RF = mejor_RF.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UiYzB_O0hdRX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f_C9aB2KJGg",
        "outputId": "162d94c6-2f71-45f5-ebd8-6d9651f18583"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-@Random Forest-\n",
            "\n",
            " Mejores parámetros:  \n",
            " - Número de árboles (estimadores):    2 \n",
            " - Número de hojas (datos)        :  500\n",
            "\n",
            " Accuracy en conjunto de prueba:    0.6699751861042184\n",
            "\n",
            " Reporte: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.86      0.75       231\n",
            "           1       0.69      0.41      0.52       172\n",
            "\n",
            "    accuracy                           0.67       403\n",
            "   macro avg       0.68      0.64      0.63       403\n",
            "weighted avg       0.67      0.67      0.65       403\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Stats\n",
        "mejores_parametros_RF = cv_RF.best_params_\n",
        "accuracy_RF = accuracy_score(y_test, y_pred_RF)\n",
        "\n",
        "# Printer\n",
        "print(\"-@Random Forest-\")\n",
        "print(\"\\n Mejores parámetros: \",\n",
        "      \"\\n - Número de árboles (estimadores):   \", list(mejores_parametros_RF.values())[0],\n",
        "      \"\\n - Número de hojas (datos)        : \",   list(mejores_parametros_RF.values())[1])\n",
        "print(\"\\n Accuracy en conjunto de prueba:   \",    accuracy_RF)\n",
        "print(\"\\n Reporte: \\n\",      classification_report(y_test, y_pred_RF))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgXr80OjoGsV"
      },
      "source": [
        "#2.\n",
        "Resuelva el problema utilizando Xgboost. Seleccione el modelo apropiado por validación cruzada. para esto entrene modelos con los siguientes parámetros:\n",
        "\n",
        "\n",
        "*   Número de árboles: Por lo menos 8 valores escogidos entre 50 y 600,\n",
        "*   Factor de encogimiento: Por lo menos 5 valores entre 0 y 1.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i_vE8FNUGca9"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qtUWTnOgohI-"
      },
      "outputs": [],
      "source": [
        "# Configurar la grilla de parámetros para XGBoost\n",
        "params_XGB = {\n",
        "    'n_estimators'    : [50, 100, 150, 200, 250, 300, 400, 600],  # Número de árboles\n",
        "    'learning_rate'   :              [0.05, 0.1, 0.2, 0.3, 0.4],  # Factor de encogimiento\n",
        "}\n",
        "\n",
        "# Crear y entrenar el clasificador XGBoost\n",
        "XGB = XGBClassifier(use_label_encoder = False, eval_metric = 'logloss')\n",
        "cv_XGB = GridSearchCV(estimator = XGB, param_grid = params_XGB) # Introducir los parámetros de validación cruzada\n",
        "cv_XGB.fit(X_train, y_train)\n",
        "\n",
        "# Seleccionar el mejor modelo\n",
        "mejor_XGB = cv_XGB.best_estimator_\n",
        "\n",
        "# Evaluar el modelo seleccionado en el conjunto de prueba\n",
        "y_pred_XGB = mejor_XGB.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odVpfJNqKE9t",
        "outputId": "aebea54c-9e4e-4362-fc30-63d81f13fac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-@XGBoost-\n",
            "\n",
            " Mejores parámetros:  \n",
            " - Número de árboles (estimadores)   : 0.05 \n",
            " - Tasa de aprendizaje (encogimiento):   50\n",
            "\n",
            " Accuracy en conjunto de prueba:     0.630272952853598\n",
            "\n",
            " Reporte: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.85      0.72       231\n",
            "           1       0.62      0.34      0.44       172\n",
            "\n",
            "    accuracy                           0.63       403\n",
            "   macro avg       0.63      0.59      0.58       403\n",
            "weighted avg       0.63      0.63      0.60       403\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Stats\n",
        "mejores_parametros_XGB = cv_XGB.best_params_\n",
        "accuracy_XGB = accuracy_score(y_test, y_pred_XGB)\n",
        "\n",
        "# Printer\n",
        "print(\"-@XGBoost-\")\n",
        "print(\"\\n Mejores parámetros: \",\n",
        "      \"\\n - Número de árboles (estimadores)   :\",           list(mejores_parametros_XGB.values())[0],\n",
        "      \"\\n - Tasa de aprendizaje (encogimiento):  \",         list(mejores_parametros_XGB.values())[1])\n",
        "print(\"\\n Accuracy en conjunto de prueba:    \",    accuracy_XGB)\n",
        "print(\"\\n Reporte: \\n\",      classification_report(y_test, y_pred_XGB))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asAl2PRSoheY"
      },
      "source": [
        "#3.\n",
        "Escriba su propia implementación de Adaboost, usando como clasificador base decision\n",
        "stumps (es decir árboles de decisión con sólo un nivel). Escriba su propia implementación de la rutina de entrenamiento de los clasificadores base. Entrene un modelo con\n",
        "600 clasificadores base y grafique curvas de errores de entrenamiento y validación que\n",
        "le permitan seleccionar un modelo con un número apropiado de clasificadores base.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rdyuAcyon4S"
      },
      "outputs": [],
      "source": [
        "def MinimizarImpureza_feature(datos, feature):\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krezWTgMf8m7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2mz6hZugTUM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9x9gG0mooM9"
      },
      "source": [
        "#4.\n",
        "Evalúe sus tres modelos resultantes en los datos de prueba con métricas apropiadas y\n",
        "compare su desempeño."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGZ635_psT_G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4ViKHlesUVO"
      },
      "source": [
        "# .\n",
        "**Entregable:** Notebook de Jupyter en que se describen sus procedimientos, resultados,\n",
        "análisis de resultados y conclusiones (y por supuesto, el código utilizado). Este informe\n",
        "debe estar bien estructurado, con buena redacción y ortografía.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "history_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
